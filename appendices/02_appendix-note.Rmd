# PROOFS OF INSTABILITY RESULTS

**Proof of Proposition \@ref(prp:instab-elpr).** We prove the contrapositive, supposing that $\Delta(\boldsymbol \theta_N) \le C$ holds for some $C > 0$ and show $\text{ELPR}(\boldsymbol \theta_N) \leq NC$. Let $\boldsymbol x_{min} \equiv \argmin\limits_{\boldsymbol x \in \mathcal{X}^N}P_{\boldsymbol \theta_N}(\boldsymbol x)$ and $\boldsymbol x_{max} \equiv \argmax\limits_{\boldsymbol x \in \mathcal{X}^N}P_{\boldsymbol \theta_N}(\boldsymbol x)$. Note there exists a sequence $\boldsymbol x_{min} \equiv \boldsymbol x_0, \boldsymbol x_1, \dots, \boldsymbol x_k \equiv \boldsymbol x_{max}$ in $\mathcal{X}^N$ of component-wise switches to move from $\boldsymbol x_{min}$ to $\boldsymbol x_{max}$ in the sample space (i.e. $\boldsymbol x_i, \boldsymbol x_{i + 1} \in \mathcal{X}^N$ differ in exactly $1$ component for $i = 0, \dots, k$) for some integer $k \in \{0, 1, \dots, N\}$. Under the FSFS model, recall $P_{\boldsymbol \theta_N}(\boldsymbol x) > 0$ holds so that $\log P_{\boldsymbol \theta_N}(\boldsymbol x)$ is well-defined for each outcome $\boldsymbol x \in \mathcal{X}^N$. Then, if $k > 0$, it follows that
\begin{align*}
\text{ELPR}(\boldsymbol \theta_N) = \log\left[\frac{P_{\boldsymbol \theta_N}(\boldsymbol x_{max})}{P_{\boldsymbol \theta_N}(\boldsymbol x_{min})}\right] &= \left|\sum\limits_{i = 1}^k\log\left(\frac{P_{\boldsymbol \theta_N}(\boldsymbol x_i)}{P_{\boldsymbol \theta_N}(\boldsymbol x_{i-1})}\right)\right| \\
&\le \sum\limits_{i = 1}^k\left|\log\left(\frac{P_{\boldsymbol \theta_N}(\boldsymbol x_i)}{P_{\boldsymbol \theta}(\boldsymbol x_{i-1})}\right)\right| \le k \Delta_N(\boldsymbol \theta_N) \le NC,
\end{align*}
using $k \le N$ and $\Delta(\boldsymbol \theta_N) \le C$. If $k = 0$, then $\boldsymbol x_{max} = \boldsymbol x_{min}$ and the same bound above holds.$\Box$

**Proof of Proposition \@ref(prp:degenFSFS).** where $|\mathcal{X}|<\infty$ holds in the FSFS model. We may suppose $|\mathcal{X}|>1$ (i.e., $\mathcal{X}^N$ has more than one outcome) because otherwise the model is trivially degenerate for all $N \geq 1$. Fix $0 < \epsilon < 1$. Then, $\boldsymbol x_{max} \in M_{\epsilon, \boldsymbol \theta_N}$, so $P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N}) \ge P_{\boldsymbol \theta_N}(\boldsymbol x_{max}) > 0$. If $\boldsymbol x \in \mathcal{X}^N \setminus M_{\epsilon, \boldsymbol \theta_N}$, then by definition $P_{\boldsymbol \theta_N}(\boldsymbol x) \le [P_{\boldsymbol \theta_N}(\boldsymbol x_{max})]^{1-\epsilon}[P_{\boldsymbol \theta_N}(\boldsymbol x_{min})]^{\epsilon}$ holds so that
\begin{align*}
1-P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N})
& = \sum\limits_{\boldsymbol x \in \mathcal{X}^N \setminus M_{\epsilon, \boldsymbol \theta_N}}P_{\boldsymbol \theta_N}(\boldsymbol x) \\
& \le (|\mathcal{X}|^N)[P_{\boldsymbol \theta_N}(\boldsymbol x_{max})]^{1-\epsilon}[P_{\boldsymbol \theta_N}(\boldsymbol x_{min})]^{\epsilon}.
\end{align*}
From the lower bound on $P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N})$ and the upper bound on $1-P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N})$, it follows that
\begin{align*}
\frac{1}{N}\log\left[\frac{P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N})}{1-P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N})}\right] & \ge \frac{1}{N} \log\left[\frac{P_{\boldsymbol\theta_N}(\boldsymbol x_{max})}{(|\mathcal{X}|^N)[P_{\boldsymbol \theta_N}(\boldsymbol x_{max})]^{1-\epsilon}[P_{\boldsymbol \theta_N}(\boldsymbol x_{min})]^{\epsilon}}\right] \\
&= \frac{\epsilon}{N} \log\left[\frac{P_{\boldsymbol \theta_N}(\boldsymbol x_{max})}{P_{\boldsymbol \theta_N}(\boldsymbol x_{min})}\right] - \log |\mathcal{X}| \rightarrow \infty
\end{align*}
as $N \rightarrow \infty$ by the definition of an unstable FSFS model (c.f. Definition \ref{defn:instab}). Consequently, $P_{\boldsymbol \theta_N}(M_{\epsilon, \boldsymbol \theta_N}) \rightarrow 1$ as $N \rightarrow \infty$ as claimed.$\Box$
